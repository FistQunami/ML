{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njQcrguya1Nb"
   },
   "source": [
    "# Кластеризация. Домашка\n",
    "\n",
    "## Совсем простая рекомендательная система\n",
    "\n",
    "На основе оценок аниме, которые ставят пользователи систем типа [MAL](https://myanimelist.net/), можно строить разные кластеры данных:\n",
    "- кластеры похожих людей. Похожие значит, что эти люди ставят похожие рейтинги аниме.\n",
    "- кластеры похожих аниме. Похожие значит что люди оценивают их похоже.\n",
    "- кластеры похожих жанров. Но похожие не в обычном смысле, а в смысле, что люди которые смотрят жанр А любят смотреть жанр Б.\n",
    "\n",
    "и т.д.\n",
    "\n",
    "### Полезная литература\n",
    "\n",
    "- [Лекция 8. Рекомендательный системы](https://www.youtube.com/watch?v=Te_6TqEhyTI&t=4s).\n",
    "- [Туториал по рекомендательным системам](http://nbviewer.jupyter.org/urls/gitlab.7bits.it/isiganov/ml-course/raw/master/week05/theory/05-01-clustering.ipynb?inline=false)\n",
    "- [ODS: Обучение без учителя: PCA и кластеризация](https://habrahabr.ru/company/ods/blog/325654/)\n",
    "- [Интересные алгоритмы кластеризации, часть первая: Affinity propagation](https://habrahabr.ru/post/321216/) и другие статьи цикла\n",
    "- [Глава 7: кластеризация и визуализация. К. В. Воронцов](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf)\n",
    "- [Документация sklearn.clustering](http://scikit-learn.org/stable/modules/clustering.html)\n",
    "- [K-Means Clustering - The Math of Intelligence. Siraj Raval](https://www.youtube.com/watch?v=9991JlKnFmk) объяснение с программированием KMeans вручную\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR2jz6_Ja1Nd"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm # Раскоментируйте если прогресс бар будет странно работать\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Зафиксируем случайность, чтобы у нас получались одинаковые результаты.\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UhBfNdTb2gD"
   },
   "source": [
    "## Анализ отзывов аниме\n",
    "\n",
    "Возьмем датасет с рейтингами аниме: https://www.kaggle.com/CooperUnion/anime-recommendations-database  \n",
    "Кстати, вы можете посмотреть kernels - это jupyter notebooks, в которых другие люди тоже делали что-то с этим датасетом.\n",
    "\n",
    "```\n",
    "Anime.csv\n",
    "\n",
    "anime_id - myanimelist.net's unique id identifying an anime.\n",
    "name - full name of anime.\n",
    "genre - comma separated list of genres for this anime.\n",
    "type - movie, TV, OVA, etc.\n",
    "episodes - how many episodes in this show. (1 if movie).\n",
    "rating - average rating out of 10 for this anime.\n",
    "members - number of community members that are in this anime's \"group\".\n",
    "\n",
    "\n",
    "Rating.csv\n",
    "\n",
    "user_id - non identifiable randomly generated user id.\n",
    "anime_id - the anime that this user has rated.\n",
    "rating - rating out of 10 this user has assigned (-1 if the user watched it but didn't assign a rating).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vRFEeThr-RBx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12017, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32281</th>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>Drama, Romance, School, Supernatural</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>9.37</td>\n",
       "      <td>200630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28977</th>\n",
       "      <td>Gintama°</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  \\\n",
       "anime_id                                     \n",
       "32281                       Kimi no Na wa.   \n",
       "5114      Fullmetal Alchemist: Brotherhood   \n",
       "28977                             Gintama°   \n",
       "9253                           Steins;Gate   \n",
       "9969                         Gintama&#039;   \n",
       "\n",
       "                                                      genre   type episodes  \\\n",
       "anime_id                                                                      \n",
       "32281                  Drama, Romance, School, Supernatural  Movie        1   \n",
       "5114      Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64   \n",
       "28977     Action, Comedy, Historical, Parody, Samurai, S...     TV       51   \n",
       "9253                                       Sci-Fi, Thriller     TV       24   \n",
       "9969      Action, Comedy, Historical, Parody, Samurai, S...     TV       51   \n",
       "\n",
       "          rating  members  \n",
       "anime_id                   \n",
       "32281       9.37   200630  \n",
       "5114        9.26   793665  \n",
       "28977       9.25   114262  \n",
       "9253        9.17   673572  \n",
       "9969        9.16   151266  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime = pd.read_csv('data/anime/anime.csv.zip', index_col='anime_id')\n",
    "anime.dropna(inplace=True)\n",
    "print(anime.shape)\n",
    "anime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c9VKgQNV-VKE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        1        20      -1\n",
       "1        1        24      -1\n",
       "2        1        79      -1\n",
       "3        1       226      -1\n",
       "4        1       241      -1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('data/anime/rating.csv.zip')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h338V2Lwb2gj"
   },
   "source": [
    "Датасет очень большой и грязный. Некоторые действия с этим датасетом будут требовать много оперативной памяти(>6 Гб).\n",
    "\n",
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e839HZu_b2gk"
   },
   "source": [
    "Во первых, в датасете есть много -1. Оценки -1 и 0 на MAL нет. \n",
    "\n",
    "Здесь -1 означает что человек посмотрел это аниме, но не выставил оценку.\n",
    "\n",
    "Такие записи из `ratings` стоит выбросить, так как в нашем случае они особо не помогут. \n",
    "\n",
    "Но и не помешают серьезно. Если хотите оставьте их, только нужно заменить все -1 на 0, так как дальше нам понадобится посчитать среднее, а -1 или 0, в отличие от `np.nan`, повлияют на среднее. \n",
    "\n",
    "### 1. Избавьтесь от -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pCRsQ18wb2gl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета после удаления -1: (6337241, 3)\n",
      "     user_id  anime_id  rating\n",
      "47         1      8074      10\n",
      "81         1     11617      10\n",
      "83         1     11757      10\n",
      "101        1     15451      10\n",
      "153        2     11771      10\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('data/anime/rating.csv.zip')\n",
    "\n",
    "ratings = ratings[ratings['rating'] != -1]\n",
    "\n",
    "print(f\"Размер датасета после удаления -1: {ratings.shape}\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm0qReHpb2gq"
   },
   "source": [
    "## Критерий Шавене (Chauvenet)\n",
    "\n",
    "[Теория](https://www.youtube.com/watch?v=Fy9pHH3ykPE&list=PLLyuiBK_HOLPfRVN6r9305FKXq1ravbbX)\n",
    "\n",
    "$$ \\operatorname{erfc}(\\frac{|P_i - mean(P)|}{S_p})  < \\frac{1}{2n}$$\n",
    "\n",
    "$ S_p - отклонение $\n",
    "\n",
    "Готовой реализации в библиотеках нет, поэтому придется написать самим(но если найдете можете использовать).\n",
    "\n",
    "`erfc` — это дополнительная функция ошибок Гаусса. [wiki](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA)\n",
    "\n",
    "$$\\operatorname{erfc}\\,x = 1-\\operatorname{erf}\\,x = \\frac{2}{\\sqrt{\\pi}} \\int\\limits_x^{\\infty} e^{-t^2}\\,\\mathrm dt$$\n",
    "\n",
    "$$\\operatorname{erf}\\,x = \\frac{2}{\\sqrt{\\pi}}\\int\\limits_0^x e^{-t^2}\\,\\mathrm dt$$\n",
    "\n",
    "### 2. Напишите функцию, которая принимает на вход массив, считает критерий Шавене и возвращает булеву маску.\n",
    "\n",
    "Функция `erfc` есть в sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SRPB9ZGVb2gr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import erfc\n",
    "\n",
    "def chauvenet(array):\n",
    "    \"\"\"\n",
    "    Функция для расчета критерия Шавене и возвращения булевой маски.\n",
    "    \n",
    "    Параметры:\n",
    "        array: numpy.array или список\n",
    "            Входные данные, для которых вычисляется критерий Шавене.\n",
    "    \n",
    "    Возвращает:\n",
    "        mask: numpy.array\n",
    "            Булева маска, где True - значения, соответствующие критерию Шавене, False - выбросы.\n",
    "    \"\"\"\n",
    "    array = np.asarray(array)  # Конвертируем входные данные в numpy массив\n",
    "    mean = np.mean(array)      # Среднее значение\n",
    "    std_dev = np.std(array)    # Стандартное отклонение\n",
    "    N = len(array)             # Количество элементов\n",
    "    \n",
    "    # Рассчитываем отклонение от среднего в сигмах\n",
    "    deviation = np.abs(array - mean) / std_dev\n",
    "    \n",
    "    # Вероятности, соответствующие отклонению\n",
    "    prob = erfc(deviation / np.sqrt(2))\n",
    "    \n",
    "    # Порог критерия Шавене\n",
    "    threshold = 1.0 / (2 * N)\n",
    "    \n",
    "    # Создаем булеву маску\n",
    "    mask = prob >= threshold\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YibqZ90_b2gv"
   },
   "source": [
    "Для начала давайте посмотрим на таблицу рейтингов.\n",
    "\n",
    "### 3. Сделайте новую таблицу `count_reviews` где индексами будет `user_id` а значением будет количество просмотренных им аниме.\n",
    "\n",
    "\n",
    "**Hint** Используйте [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) и [count](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M3XQcmqvb2gw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count_reviews\n",
      "user_id               \n",
      "1                    4\n",
      "2                    1\n",
      "3                   92\n",
      "5                  459\n",
      "7                  343\n"
     ]
    }
   ],
   "source": [
    "count_reviews = ratings.groupby('user_id')['anime_id'].count()\n",
    "\n",
    "count_reviews = count_reviews.to_frame(name='count_reviews')\n",
    "\n",
    "print(count_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCtMNEeRb2g0"
   },
   "source": [
    "### 4. Используйте функцию chauvenet и найдите все выбросы.\n",
    "\n",
    "**Hint:** Так как chauvenet возвращает маску используйте оператор `[]` (подробнее смотрите в 1 теории по pandas и numpy).\n",
    "\n",
    "**Hint:** Используйте [values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.values.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dN5Q6T87b2g2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count_reviews\n",
      "user_id               \n",
      "226                742\n",
      "446                743\n",
      "478                863\n",
      "958                783\n",
      "1145               904\n",
      "...                ...\n",
      "70953              830\n",
      "71792             1014\n",
      "73135              986\n",
      "73234              812\n",
      "73378              723\n",
      "\n",
      "[550 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "mask = chauvenet(count_reviews['count_reviews'].values)\n",
    "\n",
    "outlier_users = count_reviews[~mask]\n",
    "\n",
    "print(outlier_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMHGjMnFb2g5"
   },
   "source": [
    "### 5. Ответьте на вопросы\n",
    "\n",
    "#### Кого критерий посчитал выбросом?\n",
    "\n",
    "#### Почему критерий посчитал их выбросом?\n",
    "\n",
    "#### Нужна ли им вообще рекомендательная система?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTlAVwKjb2g6"
   },
   "source": [
    "**Ответы:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vU3CF5oqb2g6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_reviews    701\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_user_threshold = outlier_users.min()\n",
    "bad_user_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vU3CF5oqb2g6"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (837177808.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    //* outlier_users\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "//* 1: outlier_users \n",
    "Это пользователи, у которых аномально большое количество просмотренных аниме по сравнению с остальными пользователями в датасете.\n",
    "//* 2: Критерий Шавене основывается на стандартном распределении данных. \n",
    "Если значение сильно отклоняется от среднего (выражается через количество стандартных отклонений), \n",
    "то вероятность наблюдения таких данных становится очень низкой.\n",
    "В нашем случае пользователи, которые посмотрели аномально много аниме (в несколько раз больше среднего по выборке), \n",
    "попадают под это определение. Это делает их выбросами, так как они не соответствуют типичному поведению большинства пользователей.\n",
    "//* 3: Такие пользователи, скорее всего:\n",
    "- Очень активны и уже просмотрели значительное количество контента.\n",
    "- Вполне возможно, что они не нуждаются в рекомендациях, так как уже изучили большую часть доступного каталога аниме.\n",
    "- Их потребности выходят за рамки типичных пользователей, для которых и предназначена рекомендательная система.\n",
    "Таким образом, им не требуется классическая рекомендательная система, поскольку они действуют иначе и могут быть исключением.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uirpa-xWb2g9"
   },
   "source": [
    "Если все было правильно `bad_user_threshold` больше 500. \n",
    "\n",
    "Нужно выбросить всех людей у которых число просмотренных аниме больше или равно `bad_user_threshold`.\n",
    "\n",
    "### 6. Переименнуйте столбец из таблицы `count_reviews` в `count_reviews` (он там единственный). Соедините `count_reviews` и `ratings` по столбцу `user_id`. И оставьте в `ratings` только тех кто посмотрел меньше `bad_user_threshold`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DlC15OSib2g-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбцы в count_reviews: Index(['count_reviews'], dtype='object')\n",
      "user_id не найден в count_reviews. Столбцы: Index(['count_reviews'], dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['user_id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     count_reviews \u001b[38;5;241m=\u001b[39m count_reviews\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m})  \u001b[38;5;66;03m# Переименование на 'user_id'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Создаем DataFrame с только нужными столбцами\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m count_reviews_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mcount_reviews\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount_reviews\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Сливаем DataFrame с ratings на основе 'user_id'\u001b[39;00m\n\u001b[1;32m     15\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mmerge(count_reviews_cleaned, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['user_id'] not in index\""
     ]
    }
   ],
   "source": [
    "# Печатаем столбцы, чтобы понять их структуру\n",
    "print(\"Столбцы в count_reviews:\", count_reviews.columns)\n",
    "\n",
    "# Проверяем, есть ли user_id в ratings. Предполагаем, что этот столбец есть в ratings\n",
    "if 'user_id' not in count_reviews.columns:\n",
    "    print(\"user_id отсутствует в count_reviews. Добавляем столбец.\")\n",
    "    # Если 'count_reviews' нужно объединить по user_id, надо найти, как связаны эти DataFrame.\n",
    "    # Предположим, что мы можем взять информацию о user_id из другого DataFrame (например, ratings).\n",
    "    \n",
    "    # Добавляем столбец 'user_id' с исходными данными\n",
    "    count_reviews['user_id'] = ratings['user_id'][:len(count_reviews)]  # Делаем это по индексу или на основе логики\n",
    "\n",
    "# Проверяем, что теперь в count_reviews есть нужный столбец 'user_id'\n",
    "print(\"Столбцы в count_reviews после добавления user_id:\", count_reviews.columns)\n",
    "\n",
    "# Создаем DataFrame с только нужными столбцами\n",
    "count_reviews_cleaned = count_reviews[['user_id', 'count_reviews']]\n",
    "\n",
    "# Сливаем DataFrame с ratings на основе 'user_id'\n",
    "ratings = ratings.merge(count_reviews_cleaned, on='user_id', how='left')\n",
    "\n",
    "# Печатаем список столбцов в ratings, чтобы убедиться в корректности слияния\n",
    "print(\"Столбцы после merge:\", ratings.columns)\n",
    "\n",
    "# Проверяем, какие данные и пороговые значения для плохих пользователей\n",
    "print(\"bad_user_threshold:\", bad_user_threshold)\n",
    "\n",
    "# Фильтруем ratings на основе условия\n",
    "ratings = ratings[ratings['count_reviews'] < bad_user_threshold]\n",
    "\n",
    "# Печатаем результаты для отладки\n",
    "print(ratings.head())\n",
    "print(f\"Размер таблицы после фильтрации: {ratings.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oeDGjoVb2hA"
   },
   "source": [
    "Осталось все равно слишком много пользователей.\n",
    "\n",
    "### 7. Удалите из таблицы всех юзеров, у которых количество просмотров меньше медианного значения. То есть мы удалим половину юзеров.\n",
    "\n",
    "Так как они посмотрели слишком мало, чтобы мы на них могли основывать свои советы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z1mmi1vb2hB"
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### \n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psfK_Z_Nb2hE"
   },
   "outputs": [],
   "source": [
    "# Удалим столбец с просмотрами чтобы не мешал.\n",
    "\n",
    "ratings = ratings.drop(columns=['count_reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM5IUARab2hG"
   },
   "source": [
    "Теперь рассмотрим таблицу `anime`. \n",
    "\n",
    "\n",
    "Так же применим критерий шавене.\n",
    "\n",
    "Искать выбросы стоит по столбцу `rating` или по `members` или по обоим сразу.\n",
    "\n",
    "### 8. Используйте функцию chauvenet и найдите все выбросы среди аниме. И удалите их.\n",
    "\n",
    "**Hint** Используйте [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) и [index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRMPTUkib2hH"
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### \n",
    "outlier_anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPL12FNQb2hK"
   },
   "source": [
    "### 9. Ответье на вопросы\n",
    "\n",
    "#### Что критерий посчитал выбросом? \n",
    "\n",
    "#### Почему критерий посчитал их выбросом? \n",
    "\n",
    "#### Можем ли мы как то использовать эти аниме в нашей рекомендательное системе? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMz-EvSFb2hL"
   },
   "source": [
    "**Ответы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MCsZX8rb2hL"
   },
   "source": [
    "## Кластеризация по жанрам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHZyEqKl5zgm"
   },
   "source": [
    "Данные о жанре хранятся как строка, разделенная запятой `,` . Но нам нужны сами жанры. Придется поколдовать и разделить эту строку на элементы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_2Nragqa1N2"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "'''\n",
    "Нам нужна функция flatmap.\n",
    "Flatmap получает на вход список, на каждом элементе вызывает функцию f, которая возвращает другой список.\n",
    "В результате получается список списков. В конфе происходит flatten - уплощение списка скписков в один список.\n",
    "'''\n",
    "def flatmap(f, items):\n",
    "    return chain.from_iterable(map(f, items))\n",
    "\n",
    "# пример использования\n",
    "list(flatmap(lambda x: [0, x , x*x], [1,2,3,4,5]))\n",
    "# Первый шаг: [[0, 1, 1], [0, 2, 4], [0, 3, 9], [0, 4, 16], [0, 5, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMm-sCdXa1OF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# создаем функцию, которая просто разбивает строку по символу \", \" на подстроки\n",
    "def genre_splitter(genre_names):\n",
    "    return genre_names.split(\", \")\n",
    "\n",
    "m_uniq = anime['genre'].unique() # смотрим сколько всего уникальных комбинация genres есть в датасете\n",
    "print(\"m_uniq[0:10] = {}\\nlen= {}\\n\".format(m_uniq[0:10], len(m_uniq))) # как видим комбинаций очень много, так как там все композиции\n",
    "\n",
    "genres = set(flatmap(genre_splitter, m_uniq)) # разбиваем все genres на составные части и генерируем один массив из всех жанров. Строим по массиву множество уникальных жанров\n",
    "\n",
    "genres = list(genres) # множество превращаем в список\n",
    "print(\"Genres={}\\nlen={}\".format(genres, len(genres)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa6hsGvs6Plt"
   },
   "source": [
    "### 10. Создадим новую таблицу, где в колонках будет жанр, в строках аниме, а в ячейках 1 если у фильма есть этот жанр и 0 в противном случае.\n",
    "\n",
    "Такой формат таблиц называтеся one-hot-encoding. Только в нашем случае в каждой строке будет не одна единица, а несколько, так как у аниме как правило несолько жанров.\n",
    "\n",
    "Уточнение: жанры должны быть индексами столбцов (columns), а id аниме - индексами строк (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4kWGYLva1OI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r33UeY26a1OL"
   },
   "source": [
    "Итак, у нас есть следующие таблицы:\n",
    "- Жанры аниме - в строчках аниме, в столбцах жанр аниме, а в ячейках 0 или 1.\n",
    "- Рейтинги - в строчках пользователи, в столбцах id аниме и рейтинг\n",
    "\n",
    "Нужно получить другую таблицу, в которой в строках будут пользователи, а в столбцах жанры аниме. А в ячейках средняя оценка жанра этим пользователем.\n",
    "\n",
    "Средняя оценка жанра вычисляется следующим образом: берём все отзывы пользователя. Группируем все его отзывы по жанрам и считаем средний рейтинг, который он ставит аниме с данным жанром.\n",
    "\n",
    "Выполним следущие шаги.\n",
    "\n",
    "### 11. Соединим две таблицы:<br>\n",
    "1. жанры по каждому аниме<br>\n",
    "2. оценки аниме от людей. Кстати, один человек мог посмотреть 1 аниме или 100, но не все!<br>\n",
    "\n",
    "Получим таблицу, где строк будет N*M штук, где N - количество юзеров и M - количество аниме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UZ89H8ra1OM"
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd5AyQk7a1OP"
   },
   "source": [
    "С такой таблицей `(N*M) * G` вы всё еще не можем работать.  \n",
    "### 12. Сгруппируем строки по пользователям (колонка `userId`).  В группах посчитаем среднюю оценку на жанр. А если пользователь не смотрел фильм, то поставим ему `-1` в соответсвующую ячейку.\n",
    "Чтобы посчитать среднее(mean) без учета непросмотренных аниме замените все `0` на `np.NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZUl41QBa1OP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ9UuFn0b2hX"
   },
   "source": [
    "Так как некоторые пользователи не смотрели ничего из некоторых жанров, в данных осталось много `np.NaN`\n",
    "### 13. Заполните все NaN на -1\n",
    "\n",
    "**Hint** [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDoXl9XFb2hY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wo_Sod-a1OT"
   },
   "source": [
    "Прежде чем начать обучать kMeans...\n",
    "\n",
    "### 14. Отмасштабируйте признаки.\n",
    "\n",
    "Как мы знаем по лекции, метрическим алгоритмам, одним из которых и является kMeans, лучше подавать на вход данные одного масштаба.  Этим и занимается метод MinMaxScaler из sklearn.\n",
    "\n",
    "[Документация](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n",
    "Алгоритм его работы:\n",
    "```\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOjZgEy1a1OU"
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtnFeq5--WYV"
   },
   "source": [
    "### 15.Натренируйте kMeans с 10 кластерами на полученных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P8wbyKs-2ss"
   },
   "outputs": [],
   "source": [
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9Pn5DMHa1OX"
   },
   "source": [
    "### 16. Нарисуйте на графике центры кластеров нашего датасета оценок фильмов.\n",
    "\n",
    "В нем будет 10 строчек - 10 кластеров. И 43 столбцов - 43 жанров фильмов.\n",
    "\n",
    "Из графика мы поймем какие жанры обычно смотрят вместе. По сути мы получили кластеры предпочтений людей.\n",
    "\n",
    "**Hint** [Heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyGW-7-6a1OY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8kEhXm4b2hg"
   },
   "source": [
    "# Как выбрать нужное число кластеров\n",
    "\n",
    "Такие методы как KMeans, Spectral clustering, Ward hierarchical clustering, Agglomerative clustering требуют количество кластеров как параметр. Это так называемый гипер-параметр, и его должен подбирать человек. Но на что человеку опираться при выборе? На некоторый функционал \"качества\"!\n",
    "\n",
    "Вспомним идею кластеризации:\n",
    "- минимизация внутрикластерного расстояния\n",
    "- максимизация межкластерного расстояния\n",
    "\n",
    "Другими словами - кучки кучнее и дальше друг от друга.\n",
    "\n",
    "Логично, что мы хотим, чтобы точки распологались кучно возле центров своих кластеров. Но вот незадача: минимум такого функционала будет достигаться тогда, когда кластеров столько же, сколько и точек (то есть каждая точка – это кластер из одного элемента). Для решения этого вопроса (выбора числа кластеров) часто пользуются такой эвристикой: выбирают то число кластеров, начиная с которого описанный функционал $ J(C) $ падает \"уже не так быстро\". Или более формально: $$ D(k) = \\frac{|J(C_k) - J(C_{k+1})|}{|J(C_{k-1}) - J(C_k)|}  \\rightarrow \\min\\limits_k $$\n",
    "\n",
    "Где, в случае kMeans $$ J(C) = \\sum_{k=1}^K\\sum_{i~\\in~C_k} ||x_i - \\mu_k|| \\rightarrow \\min\\limits_C,$$ - сумма квадратов расстояний от точек до центроидов кластеров, к которым они относятся\n",
    "\n",
    "#### Эта ячейка может выполнятся долго!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuTFue0rb2hg"
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "N = 30\n",
    "for k in tqdm(range(1, N)):\n",
    "    kmeans = KMeans(n_clusters=k).fit(scaler.fit_transform(df))\n",
    "    inertia.append(np.sqrt(kmeans.inertia_))\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(range(1, N), inertia, marker='s');\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('$J(C_k)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulciRrtRb2hi"
   },
   "source": [
    "## Коэффициент силуэта\n",
    "\n",
    "Данный коэффициент не предполагает знания истинных меток объектов, и позволяет оценить качество кластеризации, используя только саму (неразмеченную) выборку и результат кластеризации. \n",
    "\n",
    "Сначала силуэт определяется отдельно для каждого объекта. Обозначим через $a$ - среднее расстояние от данного объекта до объектов из того же кластера, через $b$ - среднее расстояние от данного объекта до объектов из ближайшего кластера (отличного от того, в котором лежит сам объект). Тогда силуэтом данного объекта называется величина: $$s = \\frac{b - a}{\\max(a, b)}.$$ Силуэтом выборки называется средняя величина силуэта объектов данной выборки. Таким образом, силуэт показывает, насколько среднее расстояние до объектов своего кластера отличается от среднего расстояния до объектов других кластеров. Данная величина лежит в диапазоне $[-1, 1]$. Значения, близкие к -1, соответствуют плохим (разрозненным) кластеризациям, значения, близкие к нулю, говорят о том, что кластеры пересекаются и накладываются друг на друга, значения, близкие к 1, соответствуют \"плотным\" четко выделенным кластерам. Таким образом, чем больше силуэт, тем более четко выделены кластеры, и они представляют собой компактные, плотно сгруппированные облака точек.\n",
    "\n",
    "С помощью силуэта можно выбирать оптимальное число кластеров $k$ (если оно заранее неизвестно) - выбирается число кластеров, максимизирующее значение силуэта. В отличие от предыдущих метрик, силуэт зависит от формы кластеров, и достигает больших значений на более выпуклых кластерах, получаемых с помощью алгоритмов, основанных на восстановлении плотности распределения.\n",
    "\n",
    "#### Эта ячейка может выполняться долго!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkFhvnhO3TIl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "def draw_sil_score(X, range_n_clusters=[2, 3, 4, 5, 6, 10, 12, 13, 20]):\n",
    "    scores = []\n",
    "    for n_clusters in tqdm(range_n_clusters):\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        scores.append(silhouette_avg)\n",
    "    plt.plot(range_n_clusters, scores)\n",
    "    return range_n_clusters[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZXMiFpW3VVN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "draw_sil_score(scaler.fit_transform(df), range(2, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE6UbyzUb2hn"
   },
   "source": [
    "### 17. Выберите количество кластеров `k` по методам выше. Натренируйте kMeans и снова нарисуйте heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Brw66Ylb2hn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###  Ваш код  ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EidQaCQOb2hp"
   },
   "source": [
    "### 18. Порекомендуйте что-нибудь абстрактному пользователю. \n",
    "Это можно сделать разными способами. Как это сделать подумайте сами. \n",
    "\n",
    "Если затрудняетесь реализовать это в коде, распишите словами как вы бы это сделали.\n",
    "\n",
    "Возможные варианты решения:\n",
    " * в каждом кластере отсортировать жанры по тому, насколько жанр важен. \n",
    " * взять каждый кластер -> получить все аниме, которые смотрят в этом кластере -> отсортировать по рейтину.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7bgVPgPb2hp"
   },
   "outputs": [],
   "source": [
    "###  Ваш код или рассуждение или все вместе ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw_-BJfyb2hr"
   },
   "source": [
    "### Extra. Попробуйте как-нибудь улучшить эту рекомендашку. Приведите код или рассуждения на эту тему.\n",
    "\n",
    "Если писать код, то можно:\n",
    " * каждому жанру присвоить свой вес, так как одних жанров сильно много и у них разная смысловая нагрузка. Комедии и экшн встречаются очень часто и врядли кто-то только из-за этих жанров будет смотреть аниме.\n",
    " * предсказывать не по жанрам, а по аниме. Там получится очень большая размерность, так как нужно сделать one-hot-encoding по аниме, но может это даст лучше результат(спойлер: нет). (И для этого надо сделать 4 join'а, что, возможно, убьет ваш компьютер или/и мозг)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBNRaStcb2hs"
   },
   "outputs": [],
   "source": [
    "###  Ваш код или рассуждение или все вместе ### "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04-hw-clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
